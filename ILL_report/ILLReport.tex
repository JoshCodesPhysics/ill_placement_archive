\documentclass[10pt]{article}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{verbatim}
\usepackage{courier}

\author{Joshua Horswill}
\title{ILL internship report}

\begin{document}
\maketitle
\tableofcontents
\section{Introduction}
The aim of this project is to create a driver to compute the magneto-electric coupling of a multiferroic system. Multiferroic materials are defined by the possession of a coupling between at least two ferroic orders. The foci of this report are the calculations for materials that exhibit couplings between electric and magnetic properties. Specifically it would demonstrate a net magnetic moment, an intrinsic polarisation and a linear magneto-electric coupling. This is a type II multiferroic system, type I being a material whose transitions from paraelectric and ferroelectric states are distinct from magnetic transitions \cite{Hur2004}\cite{goto2004ferroelectricity}.

In order to determine this linear magneto-electric coupling for the type II material experimentally, the associated tensor $\bar{\bar{\alpha}}$ must be measured. This tensor can be described as the response of the polarisation of a system as a function of the applied magnetic field. It can simultaneously be described as the response of the magnetic order parameter as a function of the applied electric field (this parameter is given by $\vec{M} = \sum_j \vec{\mu}_j$ or for an antiferromagnetic material, $\vec{M} = \sum_j (-1)^j \vec{\mu}_j$). These responses are of course linear.

The driver processes inputs and outputs of the various ab-initio functions (discussed later) so that it can generate the computation of this tensor $\bar{\bar{\alpha}}$ from a simulation of the electronic structure.

\section{Relation of the $\bar{\bar{\alpha}}$ tensor to the exchange integral $J$}

Lev Landau introduced a physical theory that attempted to create a general model of continuous and therefore second-order phase transitions. It is versatile in that it can be used in systems that are subject to external fields. Landau proposed that the free energy of any system should be analytic, and obey the same symmetry of the Hamiltonian. This allows the generation of a phenomenological expression for the free energy as a Taylor expansion in the order parameter \cite{landau1936theory}.

Using this theory it is possible to write an expression for $\bar{\bar{\alpha}}$ in terms of the second derivative of the free energy with respect to the electric and magnetic fields ($\vec{\mathcal{E}}$ and $\vec{\mathcal{H}}$ respectively):

\begin{equation*}
\bar{\bar{\alpha}} = -\frac{\partial^2 \mathcal{F}}{\partial \vec{\mathcal{E}}\partial\vec{\mathcal{H}}}\biggr\vert_{\vec{\mathcal{E}}=\vec{0}, \vec{\mathcal{H}} = \vec{0}}
\end{equation*}

For multiferroic systems, low-energy excitations are of a magnetic nature due to the material being a magnetic insulator. This means it is possible to describe this property by implementing an effective Hamiltonian that only takes into account the magnetic degrees of freedom. One of the models that fits these requirements particularly well is the Heisenberg Hamiltonian. For example, let us suppose that a system can be described by this Hamiltonian for the Fermi level (magnetic) properties:

\begin{equation}
\hat{H} = E_0 - \sum_{\langle i,j \rangle} J_{i,j}\hat{\vec{S_i}}\cdot \hat{\vec{S_j}}
\end{equation}

where $E_0$ is the energy associated with all non-magnetic degrees of freedom and $\langle i,j \rangle$ represents nearest neighbour exchanges (since the interaction is local). By observing the polar magnetic phase in which the magneto-electric coupling occurs, it is possible to write a statistical mechanical equation of state for the free energy ($\mathcal{F} = U - TS$ where U is internal energy, T is temperature and S is entropy):

\begin{equation*}
\mathcal{F} = E_0 - \sum_{\langle i,j \rangle} J_{i,j}\langle \hat{\vec{S_i}}\cdot \hat{\vec{S_j}} \rangle - \sum_{i}g\mu_{B}\langle \hat{\vec{S_i}}\rangle \cdot \mathcal{\vec{H}} - \vec{P}\cdot \mathcal{\vec{E}} - TS
\end{equation*}

where $\langle \rangle$ denotes the thermal average of the quantity and $J_{i,j}$ represents the effective magnetic integrals between the ith and jth electron. It is known that the thermal probability of a state being occupied, in an energetically gapped system such as this, is varying very quickly as soon as the temperature $T$ is slightly different from the critical temperature $T_c$ of the transition. In the paramagnetic phase ($T > T_c$, where for all $I$, thermal energy $k_B T \gg E_I - E_0$, where $E_I$ is the energy of the Ith magnetic state) all eigenstates have an equivalent probability $P(E = E_I) = \exp(-\beta E_I)/Z \simeq 1/N$ where N is the number of magnetic eigenstates and Z is the partition function for the system. Classically $Z = \sum_{i}^{N} \exp(-\beta E_i)$ but quantum mechanically $Z =$ tr$(\exp(-\beta \hat{H}))$. Consequently, the free energy $\mathcal{F}$ is dominated by the entropy term. However, in the phase where the system is magnetically ordered ($T < T_c$), the probability $P(E = E_{ground})$ dominates so that $\mathcal{F}$ is dominated not by entropy but by the energetic term $U$. Now we can neglect the entropy contribution in the calculation of $\bar{\bar{\alpha}}$ as soon as the temperature is slightly smaller than $T_c$.

To first order, $\bar{\bar{\alpha}}$ can resultantly be written as:

\begin{equation}
	\bar{\bar{\alpha}} = \sum_{\langle i,j \rangle} \frac{\partial J_{i,j}}{\partial \vec{\mathcal{E}}}\biggr\vert_{\vec{\mathcal{E}}=\vec{0}}\otimes\biggr(\frac{\partial \langle \vec{S_i}\rangle}{\partial \vec{\mathcal{H}}}\biggr\vert_{\vec{\mathcal{H}} = \vec{0}}\cdot\langle\vec{S_j}\rangle + \langle\vec{S_i}\rangle\cdot\frac{\partial \langle \vec{S_j}\rangle}{\partial\vec{\mathcal{H}}}\biggr\vert_{\vec{\mathcal{H}}=\vec{0}}\biggr)
\end{equation}

This means that the derivative of the exchange integrals with respect to the electric field and the derivative of the local magnetic moments with respect to the magnetic field will need to be calculated. The former will require accurate ab-initio evaluation of the $J_{i,j}$ integrals and the latter can be obtained using standard spin wave calculations (see \cite{anderson1951limits,kubo1952spin,oguchi1960theory}).

Recall $\bar\bar{\alpha}$ can be written as the derivative of the polarisation as a function of the magnetic field $\frac{\partial\vec{P}}{\partial\vec{H}}$ or the derivative of the magnetic order parameter as a function of the electric field $\frac{\partial M}{\partial\vec{\mathcal{E}}}$. If $\vec{P}$ and $M$ belong to the same irreducible (symmetric) representation, $\bar{\bar{\alpha}}$ is non-zero. If this is not the case, the tensor is null. This is because $\vec{P}$ has the same symmetry as the electron density and the nuclei, and therefore always belongs to the irreducible representation of the system's symmetry group, but this is not always the case for $M$. $M$ has the same symmetry as the spin part of the ground state wave function, and could belong to any of the symmetry groups. Third-order derivative tensors could be null, since $\mathcal{F}$ must be a totally symmetric scalar quantity, but in all instances the fourth order derivative tensor is symmetrically allowed: $-\partial^4\mathcal{F}/(\partial\vec{\mathcal{E}})^2(\partial\vec{H})^2\biggr\vert_{\mathcal{E}=\vec{0}, \mathcal{H}=\vec{0}}$

\section{DFT}
Density functional theory is used because it is impossible to solve a many-body Schrödinger equation analytically. Approximations must be made to allow for a solution. Therefore a rough description of DFT is: a method of acquiring an approximate solution to the Schrödinger equation for multiple entities. First we need to reduce the number of degrees of freedom of the system using the Born-Oppenheimer approximation. Another way to reduce the degrees of freedom is to model the electron density as a density functional rather than an electronic wavefunction containing $3N$ variables (the number of coordinates of all $N$ atoms in the system). This means that the electron density becomes a function of only three variables: $x,y,z$.

Hohenburg-Kohn theorem asserts that the density of any system determines all ground-state properties of the system \cite{hohenberg1964density}. In our case the ground state energy of a many-electron system is now a functional of the density. If we obtain this functional, we consequently know the total energy of our system. It is now possible to write the energy in terms of:

\begin{itemize}
	\item Ion-electron potential energy
	\item Ion-Ion potential energy
	\item Electron-electron potential energy
	\item Kinetic energy
	\item Exchange-correlation energy
\end{itemize}

Kinetic energy is calculated using the orthonormal Kohn-Sham orbitals. The system of interacting electrons is transformed into a system of non-interacting electrons moving in an effective potential. For the ground state, this approximation for an inhomogeneous system of electrons generates self-consistent equations similar to the Hartree-Fock equations. These equations show the exchange and correlation portions of the chemical potential of the system as the aforementioned effective potentials \cite{kohn1965self}. This non-interacting problem is supposed to have the same spin-density as the real correlated problem.

The calculation of the exchange-correlation energy will be discussed later on. They are treated using correlation functionals. DFT has been proved reliable in many cases, as long as the electron-electron interaction energy is considerably less than the kinetic energy. This is not the case for strongly correlated systems i.e. when the exchange-correlation energy is dominant \cite{pickett1989electronic}. This is the property of Fermi-level electrons and their magnetic interactions. In transition metal oxides, they are localised practically on the d-orbitals of the metal ions. The Coulomb and exchange interaction energies in this case are of a larger magnitude than the electron's kinetic energy.

The domination of these interaction energies result in charge, spin or orbital occupation fluctuations that come from the competition between the different configurations in the electronic structure. The multi-configurational nature of the ground state system means that the ab-initio single-determinant method encounters accuracy issues. A different model must therefore be used to describe the effects that are dominated by these electrons \cite{gelle2009accurate}. However, for most cases, lattice geometry, dynamics and many other properties are still approximated effectively by DFT.

\section{Accurately Employing Wavefunction Correlated Methods (WCMs)}

Correlated systems are characterised by strong Coulomb repulsions, which result in wavefunctions (for ground and low lying excited states) involving many Slaters determinants. Each determinant has equivalent weight, and differs only by the spin or occupation of the Fermi level orbitals. Since all of the orbital configurations are strongly coupled, we need a model that doesn't represent the electron density as a free electron Hartree-Fock model if we want to accurately calculate effects that result from the Fermi level electrons. This means we must rely on wavefunction correlated methods that are specifically designed for these mechanisms. 

One such example is the difference-dedicated configuration interaction method (DDCI). This was born from the fact that many methods of determining the molecular properties of the ground state had difficulty treating excited states in an accurate way. Methods similar to the `full configuration interaction' approach (such as cluster methods, which include the effect of triple excitations), where all Slater determinants of the proper symmetry are included in the virtual procedure, have been extended to deal with excitation energy calculations. In other words, FCI-type methods determine the model Hamiltonian using exact diagonalization of selected configuration spaces, which can be done on embedded fragments. In general, these extended models are very effective at accurately approximating these energies, but some discrepancies appear. An example is the CC3 cluster method which generates excellent agreement with FCI results when the excited states are dominated by a single excitation, but displays considerable error when faced with a large double-excitation character. Another example is the multi-reference method CASPT2, which gives very good results for a large number of systems, but significant errors appear when there is a mixture of states with different characteristics (e.g valence and Rydberg) i.e. when the reference and outer space are not sharply separated.

DDCI solves these problems by building a configuration interaction with a small reference space, in the subspace of singles and doubles which contributes to the energy difference on the grounds of second-order perturbation considerations, i.e. a subspace defined by the `complete active space' (CAS) for all singles, and the doubles which involved at least one active orbital \cite{garcia1997application}. If faced with a system with numerous open-shells per atom (e.g high-spin manganese, cobalt, iron oxides), the computational cost of using CAS+DDCI or related methods becomes prohibitive since the size of the space to diagonalise scales exponentially with the number of magnetic electrons. We can establish a simple physical criterion to select important reference configurations, and derive from it a novel method with a strongly reduced computational cost. This is because configurations involved in the usual methods, such as the `large complete active space + single' (LCAS+S) approach, are far too numerous compared to the necessary methods for a good quality modelling of low-lying energy state physics. Something needed to change.

\subsection{Modifications of the standard WCMs and Effective Hamiltonian Criteria}

Compared to the LCAS+S, the multiple metal-to-metal and ligand-to-metal (a ligand is a core electron; the charge being transferred are electrons between ions) charge transfer configurations were removed from the reference part of the wavefunction. When comparing to the CAS+DDCI, the multiple metal-to-metal charge transfer configurations and associated screening configurations were removed. Additionally, double excitations were restricted to screening excitations on the ligand-to-metal charge transfers. This meant that the number of configurations in a magnetic interaction between two high-spin Mn(III) ions, for CAS+DDCI and LCAS+S, were reduced from approximately 10 billion and 60 billion  to 20 million respectively. This new approach is called the `selected active space' method (SAS+S); see \cite{gelle2009accurate} for more on this approach. This optimised, embedded fragment, quantum chemical {\it ab initio} method allows for analysis of the local fluctuations of magnetic couplings in manganites, which were known to be influential in the macroscopic magneto-resistance effects but not accessible experimentally.

With both methods a dynamical correlation correction on each reference determinant is included, independent of whether they are based on either the CAS or a zeroth-order multi-reference space retaining the dominant configurations for low-lying states. Highly accurate spectra are consequently obtained, from which effective-exchange integrals can be extracted using an effective Hamiltonian method. This is a Hamiltonian that acts in a reduced space and only describes a part of the eigenvalue spectrum of the true Hamiltonian. The Heisenberg Hamiltonian of Equation (1) works on fictitious electron spin variables of magnetic subsystems, describing only low-lying energy states. However, these evaluations yield energy values within the error bar of experimental inelastic neutron scattering results.

The ground and low-lying energy state eigenvalues and wavefunctions provided by these calculations are for a set of fragments designed to suit all the crystallographically independent effective interactions. One can use the described effective Hamiltonian theory to obtain a spin Hamiltonian separate from the Heisenberg one, that also works on fictitious effective electron variables but also nuclear spin variables. It typically only describes the $(2s+1)(2l+1)$ magnetic sublevels of the complete spectrum \cite{mostafanejad2014basics}. The objective for the solutions of this spin Hamiltonian is that on each fragment it mimics the eigenvalues of the system the fragment is embedded within, and that it's eigenvectors reproduce the main configurations of the ab-initio wavefunctions. The projection must be onto a subset of the zeroth-order multi-reference space chosen for the ab-initio calculation, as seen in this equation for the system wavefunction\cite{gelle2009accurate}:

\begin{equation*}
	|\psi_m\rangle = |\psi^0_m\rangle + |\psi^{ct}_m\rangle + |\psi^*_m\rangle
\end{equation*}

where $|\psi^0_m\rangle = \sum_{I}C^0_{I,m}|\Phi^0_I\rangle$, and $|\Phi^0_I\rangle$ is the zeroth order CAS reference configuration. The coefficients for each determinant are found by diagonalising the effective Hamiltonian. This projection must represent at least $\sim90\%$ of the wave function of all involved states. Once the projection operator that accommodates these requirements is chosen, it is possible to achieve this in minimising the Lagrangian with respect to the fictional effective Hamiltonian variables:

\begin{equation*}
	\min_{J_{ij}} \mathcal{L}(J_{ij}) = \min_{J_{ij}} \sum_I ||\hat{H}(J_{ij})\hat{P}|\Psi_I\rangle-E_I\hat{P}|\Psi_I\rangle||^2
\end{equation*}

$\hat{H}(J_{ij})$ is the spin Hamiltonian, $|\Psi_I\rangle$ is the wave function for the $I$th excited state and $E_I$ its energy, and $\hat{P}$ is the aforementioned projection operator. The accuracy of this chosen $\hat{H}(J_{ij})$ is insured by the fact that $\sqrt{\mathcal{L}(J_{ij})} << J_{ij}$ and about $90\%$ of the \textit{ab initio} wavefunctions are represented for all fragments.

\section{Computing the magnetic exchange term from nuclei displacement}

Iniguez argues that the lattice-mediated part of the linear magnetoelectric response of magnetic insulators is dominant in materials displaying strong magnetoelectric couplings \cite{iniguez2008first}. These insulators allow control of their magnetic properties through the manipulation of an external electric field. The magnetization induced by the application of an electric field is given by:

\begin{equation*}
	\mathcal{M}_j(\mathcal{E}) = \sum_i \bar{\bar{\alpha_{ij}}}\mathcal{E}_i
\end{equation*}

Where $\alpha$ is the linear magnetoelectric tensor, i and j label spatial directions and $\mathcal{E}$ is the electric field. The magnitude of this response is limited by the magnetic and dielectric susceptibilities as $\alpha^2_{ij} < \chi^m_{jj}\chi^d_{ii}$, suggesting that strong ME coupling occur in materials that demonstrate large dielectric and magnetic responses. Therefore large magnetoelectric effects will correlate to significant electronic hybridizations or orbital rearrangements induced by applied electric fields. This is because it will lead to a magnetic response via spin-orbit or exchange-strictive effects. Strong dielectric responses are never purely electric - they are driven by the structural changes induced by the applied field. We can deduce that large ME effects will be based on lattice-mediated mechanisms in systems where the spin-orbit coupling is relatively large. 

The magnetoelectric coupling is computed from the first derivative of the exchange integral $J$ as a function of an applied electric field $\mathcal{E}$, as seen in equation (2). The main effect of an electric field on an ionic insulator is to displace the ions (nuclei). This displacement can be computed from:
\begin{itemize}
\item The Hessian matrix of the
energy $\mathcal{H} = \frac{\partial^2 E}{\partial \mathbf{d} ^2} $ obtained
from a mean-field DFT calculation
\item The Born dynamical effective charges $q^*$ which corresponds to the second
  derivative of the energy with respect to the field and displacement
\item Newton's 2nd law
\end{itemize}

$$ q^* \mathcal{E} = \mathcal{H} d $$

which implies that the displacement induced by an electric field is

$$ d = \mathcal{H}^{-1} q^* \mathcal{E} $$

This equation also suggests that the main response of a ferroelectric compound to an applied electric field will be a geometry modification that can be evaluated by the displacement of the system ions from their equilibrium position. Computing $\mathcal{E}$ for a range of displacements allows for the numerical evaluation of the derivative of the spin Hamiltonian parameters as a function of the applied electric field:
\begin{equation*}
	\dfrac{\partial J}{\partial \mathcal{E}} = \dfrac{\partial J}{\partial d}\dfrac{\partial d}{\partial \mathcal{E}}
\end{equation*}

Practically speaking, the first step is: for a range of $\mathcal{E}$, compute the associated displacements $d$. The second step is to compute the value of $J$ for each value of the displacement. We can evaluate the Hessian and the Born charges with DFT calculations as they both depend on the whole electron density functionals. The correlation interactions among the Fermi electrons will have only negligible effects on these quantities, and so it is safe to use DFT approximations with functionals that account for the ferroelectric gap and distortions, such as a hybrid functional.

This method has successfully been applied to YMnO$_3$ using SAS+S to calculate the exchange integral for each value of the displacement, since it was designed specifically for the purpose of precise evaluation of magnetic excitations \cite{varignon2013ab}. The configuration interactions for ligand-to-metal charge transfers and screening effects were included explicitly, and so appropriate embedded fragments were implemented. It was shown that when E was applied perpendicular to the MnO$_3$ planes, $\frac{\partial J}{\partial \mathcal{E}}$  was negligible in value. When $\mathcal{E}$ was applied in-plane, the absolute value of J increases when the field is parallel to the Mn-Mn bond. However, the spin-orbit coupling plays a negligible role in the ME response, which suggests there is be a different mechanism that is responsible.

\subsection{The Simulation Environment}
The embedded fragments are designed to include the configuration states that describe the prioritised physical processes. It has been argued that in wide-gap magnetic insulators, $J$ is determined from strongly local electronic interactions involving two magnetic centers \cite{de1999local}. These fragments were embedded in an environment reproducing the main effects as the rest of the crystal (as discussed towards the end of section 4.1). To achieve this we must include the Pauli exclusion effects of surrounding electrons and the influence of a non-local Madelung potential (nuclei-electron interactions simplified through ions being approximated as a set of point charges). The exclusion effect can be modelled through a surrounding total ionic pseudopotential (TIP, see \cite{winter1987theoretical} for example usage of this method). The Madelung potential can be recreated through an array of renormalised point charges assigned to atomic positions \cite{gelle2008fast}. 


\subsection{Calculation of the displacement}
From a DFT calculation with Crystal, when the optimal geometry is obtained, print the Hessian matrix to file with the option \verb|PRINTHESS|. 


\subsection{Calculation of the J}

From a set of inputs for the software suite used for a point of the calculation
\begin{itemize}
	\item env15
	\item seward
	\item rasscf
	\item localisation
	\item matrec
	\item kinorb
	\item rasscf - ci only
	\item motra
	\item sass
	\item prop
\end{itemize}

\section{Env2Seward}
Env2Seward is a driver script that written in the earlier stages of my time at ILL, to process the output files from the ENV15 program, \texttt{prefix.env.sew0} and \texttt{prefix.env.psd}, that contain the fragment, TIP and Madelung potential coordinates and basis sets (see \cite{varignon2013ab} as well as \cite{gelle2008fast} and the associated local tools manual). It operates by parsing the input files for the atom types and ordering the data into categorised sets with homogeneous atoms and their associated basis sets from either a default path or chosen library file. They are organised into quantum fragment, pseudopotential and Madelung potential sections in a way that is readable by the SEWARD input algorithm.

\bibliographystyle{unsrt}
\bibliography{reportbib.bib}
\end{document}
